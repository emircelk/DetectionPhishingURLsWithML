# -*- coding: utf-8 -*-
"""proje(isZeksiVeriAnalizi).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pGm15Xq7-B_A_NIMfwxysrQMRqi3NMyv
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from nltk.tokenize import RegexpTokenizer
from nltk.stem.snowball import SnowballStemmer
import nltk
from sklearn.feature_extraction.text import CountVectorizer  
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB 
from sklearn import metrics
from sklearn.metrics import confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import MultinomialNB
import seaborn as sns

! pip install opendatasets
! pip install pandas

import opendatasets as od
od.download("https://www.kaggle.com/datasets/taruntiwarihp/phishing-site-urls")

df=pd.read_csv('./phishing-site-urls/phishing_site_urls.csv')

df.shape

df

x=df.Label.unique()
y=np.array([df[df['Label']=='bad'].count()[0],df[df['Label']=='good'].count()[0]])
plt.bar(x,y,color=[ 'red', 'blue'])

df[df['Label']=='bad'].count()

df[df['Label']=='good'].count()

df.info()

df.isna().sum()

df.URL.duplicated().sum()

df = df.drop_duplicates()

df.describe()

df[df['Label']=='bad'].count()

df[df['Label']=='good'].count()

df = df.rename(columns={"URL": "url", "Label": "label"})

token = RegexpTokenizer(r'[A-Za-z0-9]+')
token.tokenize(df.url[1])

df['url_tokenized'] = df.url.map(lambda t: token.tokenize(t))
df.head()

root_words = SnowballStemmer("english")
df['root_words'] = df['url_tokenized'].map(lambda l: [root_words.stem(word) for word in l])

df.sample(5)

df.info()

df['vocabs_sent'] = df['root_words'].map(lambda l: ' '.join(l))
df = df.sample(frac=1)
df.head()

bad_sites = df[df.label == 'bad']
good_sites = df[df.label == 'good']
bad_sites.head()

good_sites.head()

c = CountVectorizer()
cv = c.fit_transform(df.vocabs_sent)

print(list(c.vocabulary_)[:10])

print('The length of vocabulary', len(c.get_feature_names()))
print('The shape is', cv.shape)

Xtrain, Xtest, Ytrain, Ytest = train_test_split(cv, df.label,test_size=0.25, random_state=5)

"""**Logistic Regression**"""

lr = LogisticRegression(max_iter=507195)
lr.fit(Xtrain,Ytrain)
print(lr)

lr.score(Xtest,Ytest)

print('Testing Accuracy :',lr.score(Xtest,Ytest))
print('Training Accuracy :',lr.score(Xtrain,Ytrain))

con_mat = pd.DataFrame(confusion_matrix(lr.predict(Xtest), Ytest),
            columns = ['Predicted:Bad', 'Predicted:Good'],
            index = ['Actual:Bad', 'Actual:Good'])
print('\nCONFUSION MATRIX')
plt.figure(figsize= (6,4))
sns.heatmap(con_mat, annot = True,fmt='d')

metrics.plot_roc_curve(lr, Xtest, Ytest)
plt.show()

"""**Naive Bayes**"""

mnb = MultinomialNB()

mnb.fit(Xtrain,Ytrain)

mnb.score(Xtest,Ytest)

print('Testing Accuracy :',mnb.score(Xtest,Ytest))
print('Training Accuracy :',mnb.score(Xtrain,Ytrain))

con_mat = pd.DataFrame(confusion_matrix(mnb.predict(Xtest), Ytest),
            columns = ['Predicted:Bad', 'Predicted:Good'],
            index = ['Actual:Bad', 'Actual:Good'])
print('\nCONFUSION MATRIX')
plt.figure(figsize= (6,4))
sns.heatmap(con_mat, annot = True,fmt='d')

metrics.plot_roc_curve(mnb, Xtest, Ytest)
plt.show()

"""**SVM**"""

svc = LinearSVC().fit(Xtrain, Ytrain)
svc.score(Xtest,Ytest)

print('Testing Accuracy :',svc.score(Xtest,Ytest))
print('Training Accuracy :',svc.score(Xtrain,Ytrain))

con_mat = pd.DataFrame(confusion_matrix(svc.predict(Xtest), Ytest),
            columns = ['Predicted:Bad', 'Predicted:Good'],
            index = ['Actual:Bad', 'Actual:Good'])
print('\nCONFUSION MATRIX')
plt.figure(figsize= (6,4))
sns.heatmap(con_mat, annot = True,fmt='d')

metrics.plot_roc_curve(svc, Xtest, Ytest)
plt.show()

"""**KNN**"""

knn = KNeighborsClassifier(n_neighbors=2)
knn.fit(Xtrain, Ytrain)
print(knn)

print('Testing Accuracy :',knn.score(Xtest,Ytest))
print('Training Accuracy :',knn.score(Xtrain,Ytrain))

con_mat = pd.DataFrame(confusion_matrix(knn.predict(Xtest), Ytest),
            columns = ['Predicted:Bad', 'Predicted:Good'],
            index = ['Actual:Bad', 'Actual:Good'])
print('\nCONFUSION MATRIX')
plt.figure(figsize= (6,4))
sns.heatmap(con_mat, annot = True,fmt='d')

metrics.plot_roc_curve(knn, Xtest, Ytest)
plt.show()